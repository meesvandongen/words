{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fd19b00",
   "metadata": {},
   "source": [
    "# NOS NL Articles Dataset Documentation\n",
    "\n",
    "This notebook documents the structure, format, and contents of the `NOS_NL_articles_2015_mar_2025.feather` dataset. \n",
    "\n",
    "The dataset contains Dutch news articles from NOS (Nederlandse Omroep Stichting) spanning from 2015 to March 2025, stored in Apache Feather format for efficient data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f339d8f",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import pandas for data manipulation and other necessary libraries for analyzing the feather dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Display settings for better data exploration\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00688ca",
   "metadata": {},
   "source": [
    "## 2. Load the Feather Dataset\n",
    "\n",
    "Load the NOS_NL_articles_2015_mar_2025.feather file using pandas and display basic information about the dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049b9ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the feather dataset\n",
    "file_path = \"data/NOS_NL_articles_2015_mar_2025.feather\"\n",
    "\n",
    "print(f\"Loading dataset from: {file_path}\")\n",
    "print(f\"File exists: {os.path.exists(file_path)}\")\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    # Get file size\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    print(f\"File size: {file_size / (1024**2):.2f} MB\")\n",
    "    \n",
    "    # Load the dataset\n",
    "    df = pd.read_feather(file_path)\n",
    "    \n",
    "    print(f\"\\nDataset loaded successfully!\")\n",
    "    print(f\"Shape: {df.shape} (rows, columns)\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / (1024**2):.2f} MB\")\n",
    "else:\n",
    "    print(\"File not found! Please check the file path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da59c40",
   "metadata": {},
   "source": [
    "## 3. Examine Dataset Structure\n",
    "\n",
    "Display the dataset shape, column names, and basic structure to understand the overall organization of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066dbcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DATASET STRUCTURE ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nColumn names ({len(df.columns)} total):\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\n=== BASIC INFO ===\")\n",
    "print(df.info())\n",
    "\n",
    "print(f\"\\n=== FIRST FEW ROWS ===\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cd932b",
   "metadata": {},
   "source": [
    "## 4. Analyze Column Data Types\n",
    "\n",
    "Examine each column's data type, check for null values, and understand the data structure of each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867f41b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== COLUMN DATA TYPES AND NULL VALUES ===\")\n",
    "column_info = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Data Type': df.dtypes,\n",
    "    'Non-Null Count': df.count(),\n",
    "    'Null Count': df.isnull().sum(),\n",
    "    'Null Percentage': (df.isnull().sum() / len(df) * 100).round(2),\n",
    "    'Unique Values': [df[col].nunique() for col in df.columns]\n",
    "})\n",
    "\n",
    "print(column_info.to_string(index=False))\n",
    "\n",
    "print(f\"\\n=== SAMPLE VALUES FOR EACH COLUMN ===\")\n",
    "for col in df.columns:\n",
    "    print(f\"\\n{col} (Type: {df[col].dtype}):\")\n",
    "    print(f\"  Sample values: {df[col].dropna().head(3).tolist()}\")\n",
    "    if df[col].dtype == 'object':\n",
    "        print(f\"  Max length: {df[col].astype(str).str.len().max()}\")\n",
    "        print(f\"  Min length: {df[col].astype(str).str.len().min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3622beb6",
   "metadata": {},
   "source": [
    "## 5. Explore Article Content\n",
    "\n",
    "Sample and display article content to understand the text format, language, and typical article structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0d2726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for text content columns (likely containing article text)\n",
    "text_columns = []\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        # Check if this looks like text content\n",
    "        sample_values = df[col].dropna().head(5)\n",
    "        avg_length = df[col].astype(str).str.len().mean()\n",
    "        if avg_length > 50:  # Likely text content if average length > 50 chars\n",
    "            text_columns.append(col)\n",
    "\n",
    "print(f\"=== POTENTIAL TEXT CONTENT COLUMNS ===\")\n",
    "for col in text_columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Average length: {df[col].astype(str).str.len().mean():.1f} characters\")\n",
    "    print(f\"  Max length: {df[col].astype(str).str.len().max()} characters\")\n",
    "\n",
    "print(f\"\\n=== SAMPLE ARTICLE CONTENT ===\")\n",
    "# Display a few sample articles\n",
    "for i in range(min(3, len(df))):\n",
    "    print(f\"\\n--- Article {i+1} ---\")\n",
    "    for col in df.columns:\n",
    "        value = df.iloc[i][col]\n",
    "        if pd.isna(value):\n",
    "            print(f\"{col}: [NULL]\")\n",
    "        elif isinstance(value, str) and len(value) > 100:\n",
    "            print(f\"{col}: {value[:100]}...\")\n",
    "        else:\n",
    "            print(f\"{col}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb8ca73",
   "metadata": {},
   "source": [
    "## 6. Check Date Range and Distribution\n",
    "\n",
    "Analyze the date columns to verify the 2015-2025 range and examine the temporal distribution of articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10696829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for date columns\n",
    "date_columns = []\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower()\n",
    "    if any(keyword in col_lower for keyword in ['date', 'time', 'published', 'created']):\n",
    "        date_columns.append(col)\n",
    "    elif df[col].dtype == 'object':\n",
    "        # Check if values look like dates\n",
    "        sample = df[col].dropna().head(10)\n",
    "        try:\n",
    "            pd.to_datetime(sample)\n",
    "            date_columns.append(col)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(f\"=== POTENTIAL DATE COLUMNS ===\")\n",
    "print(f\"Found columns: {date_columns}\")\n",
    "\n",
    "for col in date_columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    try:\n",
    "        # Try to convert to datetime\n",
    "        dates = pd.to_datetime(df[col], errors='coerce')\n",
    "        valid_dates = dates.dropna()\n",
    "        \n",
    "        if len(valid_dates) > 0:\n",
    "            print(f\"  Date range: {valid_dates.min()} to {valid_dates.max()}\")\n",
    "            print(f\"  Valid dates: {len(valid_dates)}/{len(df)} ({len(valid_dates)/len(df)*100:.1f}%)\")\n",
    "            \n",
    "            # Year distribution\n",
    "            years = valid_dates.dt.year.value_counts().sort_index()\n",
    "            print(f\"  Articles per year:\")\n",
    "            for year, count in years.items():\n",
    "                print(f\"    {year}: {count}\")\n",
    "        else:\n",
    "            print(\"  No valid dates found\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error parsing dates: {e}\")\n",
    "        print(f\"  Sample values: {df[col].head(3).tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb97fcb",
   "metadata": {},
   "source": [
    "## 7. Sample Data Exploration\n",
    "\n",
    "Display sample rows and examine specific articles to understand the data quality and content format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24b8c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== RANDOM SAMPLE OF ARTICLES ===\")\n",
    "# Show a random sample of articles\n",
    "sample_df = df.sample(n=min(5, len(df)), random_state=42)\n",
    "\n",
    "for idx, (index, row) in enumerate(sample_df.iterrows()):\n",
    "    print(f\"\\n--- Sample Article {idx+1} (Row {index}) ---\")\n",
    "    for col in df.columns:\n",
    "        value = row[col]\n",
    "        if pd.isna(value):\n",
    "            print(f\"{col}: [NULL]\")\n",
    "        elif isinstance(value, str):\n",
    "            if len(value) > 200:\n",
    "                print(f\"{col}: {value[:200]}... ({len(value)} chars total)\")\n",
    "            else:\n",
    "                print(f\"{col}: {value}\")\n",
    "        else:\n",
    "            print(f\"{col}: {value}\")\n",
    "\n",
    "print(f\"\\n=== DATA QUALITY ASSESSMENT ===\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Completely empty rows: {df.isnull().all(axis=1).sum()}\")\n",
    "print(f\"Rows with all text fields filled: {df.select_dtypes(include='object').notna().all(axis=1).sum()}\")\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
    "if len(df.columns) > 1:\n",
    "    print(f\"Duplicate articles (by first text column): {df.duplicated(subset=[df.select_dtypes(include='object').columns[0]]).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d438deb7",
   "metadata": {},
   "source": [
    "## 8. Dataset Statistics and Summary\n",
    "\n",
    "Generate descriptive statistics, word counts, and other relevant metrics to summarize the dataset characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc46fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== DATASET SUMMARY STATISTICS ===\")\n",
    "\n",
    "# Text length statistics for string columns\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    lengths = df[col].astype(str).str.len()\n",
    "    print(f\"\\n{col} - Text Length Statistics:\")\n",
    "    print(f\"  Mean: {lengths.mean():.1f} characters\")\n",
    "    print(f\"  Median: {lengths.median():.1f} characters\") \n",
    "    print(f\"  Min: {lengths.min()} characters\")\n",
    "    print(f\"  Max: {lengths.max()} characters\")\n",
    "    print(f\"  Standard deviation: {lengths.std():.1f}\")\n",
    "\n",
    "# Word count analysis for likely content columns\n",
    "print(f\"\\n=== WORD COUNT ANALYSIS ===\")\n",
    "for col in text_columns:\n",
    "    word_counts = df[col].astype(str).str.split().str.len()\n",
    "    print(f\"\\n{col} - Word Count Statistics:\")\n",
    "    print(f\"  Mean: {word_counts.mean():.1f} words\")\n",
    "    print(f\"  Median: {word_counts.median():.1f} words\")\n",
    "    print(f\"  Min: {word_counts.min()} words\")\n",
    "    print(f\"  Max: {word_counts.max()} words\")\n",
    "\n",
    "print(f\"\\n=== FINAL SUMMARY ===\")\n",
    "print(f\"Dataset: NOS_NL_articles_2015_mar_2025.feather\")\n",
    "print(f\"Total articles: {len(df):,}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "print(f\"File format: Apache Feather (.feather)\")\n",
    "print(f\"Primary language: Dutch (Nederlandse)\")\n",
    "print(f\"Source: NOS (Nederlandse Omroep Stichting)\")\n",
    "print(f\"Time period: 2015 to March 2025\")\n",
    "print(f\"Storage efficiency: {df.memory_usage(deep=True).sum() / (1024**2):.1f} MB in memory\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
